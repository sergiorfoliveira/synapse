{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "wssynapse30062022"
		},
		"AzureBlobStorage2_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'AzureBlobStorage2'"
		},
		"wssynapse30062022-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'wssynapse30062022-WorkspaceDefaultSqlServer'"
		},
		"wssynapse30062022-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://sasynapse30062022.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/AzureBlobStorage2')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"connectionString": "[parameters('AzureBlobStorage2_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/wssynapse30062022-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('wssynapse30062022-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/wssynapse30062022-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('wssynapse30062022-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0,
							"cleanup": true
						},
						"pipelineExternalComputeScaleProperties": {
							"timeToLive": 60
						}
					}
				},
				"managedVirtualNetwork": {
					"type": "ManagedVirtualNetworkReference",
					"referenceName": "default"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "Select     \n    DB_NAME(s.database_id) as DBName, \n    COUNT(s.database_id) as NumberOfConnections,\n    nt_user_name as username, \n    login_name as LoginName,\n    program_name as ApplicationName \nFROM \n    sys.dm_exec_requests req\n    JOIN sys.dm_exec_sessions s ON req.session_id = s.session_id\nGROUP BY \n    s.database_id, nt_user_name, login_name, program_name",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "LDB1",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 2')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT ID_CONTRIBUINTE, COUNT(*)\n FROM [LDB4].[dbo].[csv_poc_ms_amostra_dataset_2022_08_22]\n GROUP BY ID_CONTRIBUINTE\n HAVING COUNT(*)>1\n \n ",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "LDB4",
						"poolName": "Built-in"
					},
					"resultLimit": -1
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 3')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "LDB1",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 4')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT TOP (100) [ID_CONTRIBUINTE]\n,[TOTAL_E12]\n,[TOTAL_PRODUTO_E12]\n,[TOTAL_INTERESTADUAIS_E12]\n,[TOTAL_INTERNAS_E12]\n,[TOTAL_ICMS_E12]\n,[TOTAL_S12]\n,[TOTAL_PRODUTO_S12]\n,[TOTAL_INTERESTADUAIS_S12]\n,[TOTAL_INTERNAS_S12]\n,[TOTAL_ICMS_S12]\n,[TOTAL_NFCE_12]\n,[NE12_NS12]\n,[NE12_NFCE12]\n,[D12_NE12]\n,[D12_NS12]\n,[NE3_NE12]\n,[CS_NE12]\n,[A12_NE12]\n,[ARRECADACAO_12]\n,[DECLARADOS_12]\n,[DECLARACOES_12_PERCENTUAL]\n,[COD_CONDICAO_CONTRB]\n,[COD_SETOR_ECONOMICO_CONTRIB]\n,[COD_SEGMENTO_ECONOMICO_CONTRIB]\n,[COD_SUBSEGMENTO_ECONOM_CONTRIB]\n,[COD_PORTE_ECONOMICO_CONTRIB]\n,[TEMPO_OPERACAO]\n,[VAL_CAPITAL_SOCIAL_DECLARADO_EMPRESA]\n,[VAL_MEDIO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES]\n,[VAL_DESVIO_PADRAO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES]\n,[VAL_MVA_ANO_CALENDARIO]\n,[VAL_SALDO_FLUXO_FINANCEIRO_EMPRESA]\n,[UF]\n,[MUNICIPIO]\n,[PRINCIPAL_PRODUTO_VENDIDO]\n,[PESO_PRODUTO_VENDAS]\n,[PRINCIPAL_PRODUTO_COMPRADO]\n,[PESO_PRODUTO_COMPRAS]\n,[PRINCIPAL_FORNECEDOR]\n,[PESO_FORNECEDOR]\n,[PESO_NO_FORNECEDOR]\n,[PRINCIPAL_CLIENTE]\n,[PESO_CLIENTE]\n,[PESO_NO_CLIENTE]\n,[CONTADOR_RESPONSAVEL_NFE]\n,[FORNECEDOR_INSCRITO]\n,[DTR_REFERENCIA_PROCESSAMENTO_ROTINA_MALHA_FISCAL_F]\n,[COD_FORMA_PAGTO_F]\n,[COD_CONDICAO_CONTRB_F]\n,[COD_SETOR_ECONOMICO_CONTRIB_F]\n,[COD_SEGMENTO_ECONOMICO_CONTRIB_F]\n,[COD_SUBSEGMENTO_ECONOM_CONTRIB_F]\n,[COD_PORTE_ECONOMICO_CONTRIB_F]\n,[DTR_INICIO_OPERACAO_EMPRESA_F]\n,[VAL_CAPITAL_SOCIAL_DECLARADO_EMPRESA_F]\n,[VAL_MEDIO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_F]\n,[VAL_DESVIO_PADRAO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_F]\n,[VAL_MVA_ANO_CALENDARIO_F]\n,[VAL_SALDO_FLUXO_FINANCEIRO_EMPRESA_F]\n,[CLIENTE_INSCRITO]\n,[DTR_REFERENCIA_PROCESSAMENTO_ROTINA_MALHA_FISCAL_C]\n,[COD_FORMA_PAGTO_C]\n,[COD_CONDICAO_CONTRB_C]\n,[COD_SETOR_ECONOMICO_CONTRIB_C]\n,[COD_SEGMENTO_ECONOMICO_CONTRIB_C]\n,[COD_SUBSEGMENTO_ECONOM_CONTRIB_C]\n,[COD_PORTE_ECONOMICO_CONTRIB_C]\n,[DTR_INICIO_OPERACAO_EMPRESA_C]\n,[VAL_CAPITAL_SOCIAL_DECLARADO_EMPRESA_C]\n,[VAL_MEDIO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_C]\n,[VAL_DESVIO_PADRAO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_C]\n,[VAL_MVA_ANO_CALENDARIO_C]\n,[VAL_SALDO_FLUXO_FINANCEIRO_EMPRESA_C]\n,[TARGET]\n,[MT_RANDOM]\n,[SELECAO]\n FROM [LDB4].[dbo].[csv_poc_ms_amostra_dataset_2022_08_22_V7]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "LDB4",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 5')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "IF NOT EXISTS (SELECT * FROM sys.external_file_formats WHERE name = 'SynapseDelimitedTextFormat') \n\tCREATE EXTERNAL FILE FORMAT [SynapseDelimitedTextFormat] \n\tWITH ( FORMAT_TYPE = DELIMITEDTEXT ,\n\t       FORMAT_OPTIONS (\n\t\t\t FIELD_TERMINATOR = '\t',\n\t\t\t USE_TYPE_DEFAULT = FALSE\n\t\t\t))\nGO\n\nIF NOT EXISTS (SELECT * FROM sys.external_data_sources WHERE name = 'fssynapse30062022_sasynapse30062022_dfs_core_windows_net') \n\tCREATE EXTERNAL DATA SOURCE [fssynapse30062022_sasynapse30062022_dfs_core_windows_net] \n\tWITH (\n\t\tLOCATION = 'abfss://fssynapse30062022@sasynapse30062022.dfs.core.windows.net' \n\t)\nGO\n\nCREATE EXTERNAL TABLE table2 (\n\t[ID_CONTRIBUINTE] bigint,\n\t[TOTAL_E12] float,\n\t[TOTAL_PRODUTO_E12] float,\n\t[TOTAL_INTERESTADUAIS_E12] float,\n\t[TOTAL_INTERNAS_E12] float,\n\t[TOTAL_ICMS_E12] float,\n\t[TOTAL_S12] float,\n\t[TOTAL_PRODUTO_S12] float,\n\t[TOTAL_INTERESTADUAIS_S12] float,\n\t[TOTAL_INTERNAS_S12] float,\n\t[TOTAL_ICMS_S12] float,\n\t[TOTAL_NFCE_12] float,\n\t[NE12_NS12] float,\n\t[NE12_NFCE12] float,\n\t[D12_NE12] float,\n\t[D12_NS12] float,\n\t[NE3_NE12] float,\n\t[CS_NE12] float,\n\t[A12_NE12] float,\n\t[ARRECADACAO_12] float,\n\t[DECLARADOS_12] float,\n\t[DECLARACOES_12_PERCENTUAL] float,\n\t[COD_CONDICAO_CONTRB] bigint,\n\t[COD_SETOR_ECONOMICO_CONTRIB] bigint,\n\t[COD_SEGMENTO_ECONOMICO_CONTRIB] bigint,\n\t[COD_SUBSEGMENTO_ECONOM_CONTRIB] bigint,\n\t[COD_PORTE_ECONOMICO_CONTRIB] bigint,\n\t[TEMPO_OPERACAO] bigint,\n\t[VAL_CAPITAL_SOCIAL_DECLARADO_EMPRESA] float,\n\t[VAL_MEDIO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES] float,\n\t[VAL_DESVIO_PADRAO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES] float,\n\t[VAL_MVA_ANO_CALENDARIO] float,\n\t[VAL_SALDO_FLUXO_FINANCEIRO_EMPRESA] float,\n\t[UF] nvarchar(4000),\n\t[MUNICIPIO] nvarchar(4000),\n\t[PRINCIPAL_PRODUTO_VENDIDO] nvarchar(4000),\n\t[PESO_PRODUTO_VENDAS] float,\n\t[PRINCIPAL_PRODUTO_COMPRADO] nvarchar(4000),\n\t[PESO_PRODUTO_COMPRAS] float,\n\t[PRINCIPAL_FORNECEDOR] bigint,\n\t[PESO_FORNECEDOR] float,\n\t[PESO_NO_FORNECEDOR] float,\n\t[PRINCIPAL_CLIENTE] bigint,\n\t[PESO_CLIENTE] float,\n\t[PESO_NO_CLIENTE] float,\n\t[CONTADOR_RESPONSAVEL_NFE] bigint,\n\t[FORNECEDOR_INSCRITO] bigint,\n\t[DTR_REFERENCIA_PROCESSAMENTO_ROTINA_MALHA_FISCAL_F] bigint,\n\t[COD_FORMA_PAGTO_F] bigint,\n\t[COD_CONDICAO_CONTRB_F] bigint,\n\t[COD_SETOR_ECONOMICO_CONTRIB_F] bigint,\n\t[COD_SEGMENTO_ECONOMICO_CONTRIB_F] bigint,\n\t[COD_SUBSEGMENTO_ECONOM_CONTRIB_F] bigint,\n\t[COD_PORTE_ECONOMICO_CONTRIB_F] bigint,\n\t[DTR_INICIO_OPERACAO_EMPRESA_F] bigint,\n\t[VAL_CAPITAL_SOCIAL_DECLARADO_EMPRESA_F] float,\n\t[VAL_MEDIO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_F] float,\n\t[VAL_DESVIO_PADRAO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_F] float,\n\t[VAL_MVA_ANO_CALENDARIO_F] float,\n\t[VAL_SALDO_FLUXO_FINANCEIRO_EMPRESA_F] float,\n\t[CLIENTE_INSCRITO] bigint,\n\t[DTR_REFERENCIA_PROCESSAMENTO_ROTINA_MALHA_FISCAL_C] bigint,\n\t[COD_FORMA_PAGTO_C] bigint,\n\t[COD_CONDICAO_CONTRB_C] bigint,\n\t[COD_SETOR_ECONOMICO_CONTRIB_C] bigint,\n\t[COD_SEGMENTO_ECONOMICO_CONTRIB_C] bigint,\n\t[COD_SUBSEGMENTO_ECONOM_CONTRIB_C] bigint,\n\t[COD_PORTE_ECONOMICO_CONTRIB_C] bigint,\n\t[DTR_INICIO_OPERACAO_EMPRESA_C] bigint,\n\t[VAL_CAPITAL_SOCIAL_DECLARADO_EMPRESA_C] float,\n\t[VAL_MEDIO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_C] float,\n\t[VAL_DESVIO_PADRAO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_C] float,\n\t[VAL_MVA_ANO_CALENDARIO_C] float,\n\t[VAL_SALDO_FLUXO_FINANCEIRO_EMPRESA_C] float,\n\t[TARGET] bigint,\n\t[MT_RANDOM] float,\n\t[SELECAO] nvarchar(4000)\n\t)\n\tWITH (\n\tLOCATION = 'LakeDatabase1/DADOS_POC_ANONIMIZADO_ENTRADA_S2_v2.csv',\n\tDATA_SOURCE = [fssynapse30062022_sasynapse30062022_dfs_core_windows_net],\n\tFILE_FORMAT = [SynapseDelimitedTextFormat]\n\t)\nGO\n\n\nSELECT TOP 100 * FROM dbo.table2\nGO",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "LDB4",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 6')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT COUNT(ID_CONTRIBUINTE)\n FROM [LDB4].[dbo].[DADOS_POC_ANONIMIZADO_ENTRADA_S2_v2]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "LDB4",
						"poolName": "Built-in"
					},
					"resultLimit": -1
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 7')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT TOP (100) [ID_CONTRIBUINTE]\n,[TOTAL_E12]\n,[TOTAL_PRODUTO_E12]\n,[TOTAL_INTERESTADUAIS_E12]\n,[TOTAL_INTERNAS_E12]\n,[TOTAL_ICMS_E12]\n,[TOTAL_S12]\n,[TOTAL_PRODUTO_S12]\n,[TOTAL_INTERESTADUAIS_S12]\n,[TOTAL_INTERNAS_S12]\n,[TOTAL_ICMS_S12]\n,[TOTAL_NFCE_12]\n,[NE12_NS12]\n,[NE12_NFCE12]\n,[D12_NE12]\n,[D12_NS12]\n,[NE3_NE12]\n,[CS_NE12]\n,[A12_NE12]\n,[ARRECADACAO_12]\n,[DECLARADOS_12]\n,[DECLARACOES_12_PERCENTUAL]\n,[COD_CONDICAO_CONTRB]\n,[COD_SETOR_ECONOMICO_CONTRIB]\n,[COD_SEGMENTO_ECONOMICO_CONTRIB]\n,[COD_SUBSEGMENTO_ECONOM_CONTRIB]\n,[COD_PORTE_ECONOMICO_CONTRIB]\n,[TEMPO_OPERACAO]\n,[VAL_CAPITAL_SOCIAL_DECLARADO_EMPRESA]\n,[VAL_MEDIO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES]\n,[VAL_DESVIO_PADRAO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES]\n,[VAL_MVA_ANO_CALENDARIO]\n,[VAL_SALDO_FLUXO_FINANCEIRO_EMPRESA]\n,[UF]\n,[MUNICIPIO]\n,[PRINCIPAL_PRODUTO_VENDIDO]\n,[PESO_PRODUTO_VENDAS]\n,[PRINCIPAL_PRODUTO_COMPRADO]\n,[PESO_PRODUTO_COMPRAS]\n,[PRINCIPAL_FORNECEDOR]\n,[PESO_FORNECEDOR]\n,[PESO_NO_FORNECEDOR]\n,[PRINCIPAL_CLIENTE]\n,[PESO_CLIENTE]\n,[PESO_NO_CLIENTE]\n,[CONTADOR_RESPONSAVEL_NFE]\n,[FORNECEDOR_INSCRITO]\n,[DTR_REFERENCIA_PROCESSAMENTO_ROTINA_MALHA_FISCAL_F]\n,[COD_FORMA_PAGTO_F]\n,[COD_CONDICAO_CONTRB_F]\n,[COD_SETOR_ECONOMICO_CONTRIB_F]\n,[COD_SEGMENTO_ECONOMICO_CONTRIB_F]\n,[COD_SUBSEGMENTO_ECONOM_CONTRIB_F]\n,[COD_PORTE_ECONOMICO_CONTRIB_F]\n,[DTR_INICIO_OPERACAO_EMPRESA_F]\n,[VAL_CAPITAL_SOCIAL_DECLARADO_EMPRESA_F]\n,[VAL_MEDIO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_F]\n,[VAL_DESVIO_PADRAO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_F]\n,[VAL_MVA_ANO_CALENDARIO_F]\n,[VAL_SALDO_FLUXO_FINANCEIRO_EMPRESA_F]\n,[CLIENTE_INSCRITO]\n,[DTR_REFERENCIA_PROCESSAMENTO_ROTINA_MALHA_FISCAL_C]\n,[COD_FORMA_PAGTO_C]\n,[COD_CONDICAO_CONTRB_C]\n,[COD_SETOR_ECONOMICO_CONTRIB_C]\n,[COD_SEGMENTO_ECONOMICO_CONTRIB_C]\n,[COD_SUBSEGMENTO_ECONOM_CONTRIB_C]\n,[COD_PORTE_ECONOMICO_CONTRIB_C]\n,[DTR_INICIO_OPERACAO_EMPRESA_C]\n,[VAL_CAPITAL_SOCIAL_DECLARADO_EMPRESA_C]\n,[VAL_MEDIO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_C]\n,[VAL_DESVIO_PADRAO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_C]\n,[VAL_MVA_ANO_CALENDARIO_C]\n,[VAL_SALDO_FLUXO_FINANCEIRO_EMPRESA_C]\n,[TARGET]\n,[MT_RANDOM]\n,[SELECAO]\n FROM [LDB4].[dbo].[DADOS_POC_ANONIMIZADO_ENTRADA_S2_v2_validacao]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "LDB4",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 8')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT TOP (100) [ID_CONTRIBUINTE]\n,[TOTAL_E12]\n,[TOTAL_PRODUTO_E12]\n,[TOTAL_INTERESTADUAIS_E12]\n,[TOTAL_INTERNAS_E12]\n,[TOTAL_ICMS_E12]\n,[TOTAL_S12]\n,[TOTAL_PRODUTO_S12]\n,[TOTAL_INTERESTADUAIS_S12]\n,[TOTAL_INTERNAS_S12]\n,[TOTAL_ICMS_S12]\n,[TOTAL_NFCE_12]\n,[NE12_NS12]\n,[NE12_NFCE12]\n,[D12_NE12]\n,[D12_NS12]\n,[NE3_NE12]\n,[CS_NE12]\n,[A12_NE12]\n,[ARRECADACAO_12]\n,[DECLARADOS_12]\n,[DECLARACOES_12_PERCENTUAL]\n,[COD_CONDICAO_CONTRB]\n,[COD_SETOR_ECONOMICO_CONTRIB]\n,[COD_SEGMENTO_ECONOMICO_CONTRIB]\n,[COD_SUBSEGMENTO_ECONOM_CONTRIB]\n,[COD_PORTE_ECONOMICO_CONTRIB]\n,[TEMPO_OPERACAO]\n,[VAL_CAPITAL_SOCIAL_DECLARADO_EMPRESA]\n,[VAL_MEDIO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES]\n,[VAL_DESVIO_PADRAO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES]\n,[VAL_MVA_ANO_CALENDARIO]\n,[VAL_SALDO_FLUXO_FINANCEIRO_EMPRESA]\n,[UF]\n,[MUNICIPIO]\n,[PRINCIPAL_PRODUTO_VENDIDO]\n,[PESO_PRODUTO_VENDAS]\n,[PRINCIPAL_PRODUTO_COMPRADO]\n,[PESO_PRODUTO_COMPRAS]\n,[PRINCIPAL_FORNECEDOR]\n,[PESO_FORNECEDOR]\n,[PESO_NO_FORNECEDOR]\n,[PRINCIPAL_CLIENTE]\n,[PESO_CLIENTE]\n,[PESO_NO_CLIENTE]\n,[CONTADOR_RESPONSAVEL_NFE]\n,[FORNECEDOR_INSCRITO]\n,[DTR_REFERENCIA_PROCESSAMENTO_ROTINA_MALHA_FISCAL_F]\n,[COD_FORMA_PAGTO_F]\n,[COD_CONDICAO_CONTRB_F]\n,[COD_SETOR_ECONOMICO_CONTRIB_F]\n,[COD_SEGMENTO_ECONOMICO_CONTRIB_F]\n,[COD_SUBSEGMENTO_ECONOM_CONTRIB_F]\n,[COD_PORTE_ECONOMICO_CONTRIB_F]\n,[DTR_INICIO_OPERACAO_EMPRESA_F]\n,[VAL_CAPITAL_SOCIAL_DECLARADO_EMPRESA_F]\n,[VAL_MEDIO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_F]\n,[VAL_DESVIO_PADRAO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_F]\n,[VAL_MVA_ANO_CALENDARIO_F]\n,[VAL_SALDO_FLUXO_FINANCEIRO_EMPRESA_F]\n,[CLIENTE_INSCRITO]\n,[DTR_REFERENCIA_PROCESSAMENTO_ROTINA_MALHA_FISCAL_C]\n,[COD_FORMA_PAGTO_C]\n,[COD_CONDICAO_CONTRB_C]\n,[COD_SETOR_ECONOMICO_CONTRIB_C]\n,[COD_SEGMENTO_ECONOMICO_CONTRIB_C]\n,[COD_SUBSEGMENTO_ECONOM_CONTRIB_C]\n,[COD_PORTE_ECONOMICO_CONTRIB_C]\n,[DTR_INICIO_OPERACAO_EMPRESA_C]\n,[VAL_CAPITAL_SOCIAL_DECLARADO_EMPRESA_C]\n,[VAL_MEDIO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_C]\n,[VAL_DESVIO_PADRAO_ARRECADACAO_ICMS_ULTIMO_DOZE_MES_C]\n,[VAL_MVA_ANO_CALENDARIO_C]\n,[VAL_SALDO_FLUXO_FINANCEIRO_EMPRESA_C]\n,[TARGET]\n,[MT_RANDOM]\n,[SELECAO]\n FROM [LDB4].[dbo].[DADOS_POC_ANONIMIZADO_ENTRADA_S2_v2]",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "LDB4",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 9')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT * FROM sys.database_principals",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "LDB4",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ML Experiment')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkPool01",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "487fd595-02ab-4e6e-929e-357937299cfe"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/241719b7-f326-42c8-87a0-fb0182d3a3c7/resourceGroups/rgsynapse30062022/providers/Microsoft.Synapse/workspaces/wssynapse30062022/bigDataPools/SparkPool01",
						"name": "SparkPool01",
						"type": "Spark",
						"endpoint": "https://wssynapse30062022.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkPool01",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import azureml.core\n",
							"\n",
							"from azureml.core import Experiment, Workspace, Dataset, Datastore\n",
							"from azureml.train.automl import AutoMLConfig\n",
							"from notebookutils import mssparkutils\n",
							"from azureml.data.dataset_factory import TabularDatasetFactory"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"source": [
							"linkedService_name = \"AzureMLService1\"\n",
							"experiment_name = \"Experiment_27_08_2022_19_00\"\n",
							"\n",
							"ws = mssparkutils.azureML.getWorkspace(linkedService_name)\n",
							"experiment = Experiment(ws, experiment_name)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"df = spark.sql(\"SELECT * FROM LakeDatabase.csv_poc_ms_amostra_dataset_2022_08_22\")\n",
							"\n",
							"datastore = Datastore.get_default(ws)\n",
							"dataset = TabularDatasetFactory.register_spark_dataframe(df, datastore, name = experiment_name + \"-dataset\")"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"automl_config = AutoMLConfig(spark_context = sc,\n",
							"                             task = \"classification\",\n",
							"                             training_data = dataset,\n",
							"                             label_column_name = \"TARGET\",\n",
							"                             primary_metric = \"accuracy\",\n",
							"                             experiment_timeout_hours = 3,\n",
							"                             max_concurrent_iterations = 2,\n",
							"                             enable_onnx_compatible_models = False)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"run = experiment.submit(automl_config)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"displayHTML(\"<a href={} target='_blank'>Your experiment in Azure Machine Learning portal: {}</a>\".format(run.get_portal_url(), run.id))"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"run.wait_for_completion()\n",
							"\n",
							"import mlflow\n",
							"\n",
							"# Get best model from automl run\n",
							"best_run, non_onnx_model = run.get_output()\n",
							"\n",
							"artifact_path = experiment_name + \"_artifact\"\n",
							"\n",
							"mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
							"mlflow.set_experiment(experiment_name)\n",
							"\n",
							"with mlflow.start_run() as run:\n",
							"    # Save the model to the outputs directory for capture\n",
							"    mlflow.sklearn.log_model(non_onnx_model, artifact_path)\n",
							"\n",
							"    # Register the model to AML model registry\n",
							"    mlflow.register_model(\"runs:/\" + run.info.run_id + \"/\" + artifact_path, \"wssynapse30062022-csv_poc_ms_amostra_dataset_2022_08_22-20220827100132-Best\")"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 1')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkPool01",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "b3d839f4-2d64-4ed7-b3a5-133033da7f3a"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/241719b7-f326-42c8-87a0-fb0182d3a3c7/resourceGroups/rgsynapse30062022/providers/Microsoft.Synapse/workspaces/wssynapse30062022/bigDataPools/SparkPool01",
						"name": "SparkPool01",
						"type": "Spark",
						"endpoint": "https://wssynapse30062022.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkPool01",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							}
						},
						"source": [
							"%%pyspark\n",
							"df = spark.sql(\"SELECT * FROM `LDB4`.`csv_poc_ms_amostra_dataset_2022_08_22_V7`\")\n",
							"# df.show(10)"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.show(10)\r\n",
							""
						],
						"outputs": [],
						"execution_count": 2
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 2')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkPool02",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 1,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "4",
						"spark.autotune.trackingId": "2544e250-070e-42e4-a2dc-92a09b1c7016"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/241719b7-f326-42c8-87a0-fb0182d3a3c7/resourceGroups/rgsynapse30062022/providers/Microsoft.Synapse/workspaces/wssynapse30062022/bigDataPools/SparkPool02",
						"name": "SparkPool02",
						"type": "Spark",
						"endpoint": "https://wssynapse30062022.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkPool02",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import azureml.core\n",
							"\n",
							"from azureml.core import Experiment, Workspace, Dataset, Datastore\n",
							"from azureml.train.automl import AutoMLConfig\n",
							"from notebookutils import mssparkutils\n",
							"from azureml.data.dataset_factory import TabularDatasetFactory"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"source": [
							"linkedService_name = \"AzureMLService1\"\n",
							"experiment_name = \"wssynapse30062022-csv_poc_ms_amostra_dataset_2022_08_22_V7-20220830113644\"\n",
							"\n",
							"ws = mssparkutils.azureML.getWorkspace(linkedService_name)\n",
							"experiment = Experiment(ws, experiment_name)"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"source": [
							"df = spark.sql(\"SELECT * FROM LDB4.csv_poc_ms_amostra_dataset_2022_08_22_V7\")\n",
							"\n",
							"datastore = Datastore.get_default(ws)\n",
							"dataset = TabularDatasetFactory.register_spark_dataframe(df, datastore, name = experiment_name + \"-dataset\")"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"automl_config = AutoMLConfig(spark_context = sc,\n",
							"                             task = \"classification\",\n",
							"                             training_data = dataset,\n",
							"                             label_column_name = \"TARGET\",\n",
							"                             primary_metric = \"accuracy\",\n",
							"                             experiment_timeout_hours = 3,\n",
							"                             max_concurrent_iterations = 2,\n",
							"                             enable_onnx_compatible_models = False)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"run = experiment.submit(automl_config)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"displayHTML(\"<a href={} target='_blank'>Your experiment in Azure Machine Learning portal: {}</a>\".format(run.get_portal_url(), run.id))"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"source": [
							"run.wait_for_completion()\n",
							"\n",
							"import mlflow\n",
							"\n",
							"# Get best model from automl run\n",
							"best_run, non_onnx_model = run.get_output()\n",
							"\n",
							"artifact_path = experiment_name + \"_artifact\"\n",
							"\n",
							"mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
							"mlflow.set_experiment(experiment_name)\n",
							"\n",
							"with mlflow.start_run() as run:\n",
							"    # Save the model to the outputs directory for capture\n",
							"    mlflow.sklearn.log_model(non_onnx_model, artifact_path)\n",
							"\n",
							"    # Register the model to AML model registry\n",
							"    mlflow.register_model(\"runs:/\" + run.info.run_id + \"/\" + artifact_path, \"wssynapse30062022-csv_poc_ms_amostra_dataset_2022_08_22_V7-20220830113644-Best\")"
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Notebook 3')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkPool02",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 1,
					"conf": {
						"spark.dynamicAllocation.enabled": "true",
						"spark.dynamicAllocation.minExecutors": "1",
						"spark.dynamicAllocation.maxExecutors": "4",
						"spark.autotune.trackingId": "13b02a24-377d-41ea-b053-ec5b9b49f073"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/241719b7-f326-42c8-87a0-fb0182d3a3c7/resourceGroups/rgsynapse30062022/providers/Microsoft.Synapse/workspaces/wssynapse30062022/bigDataPools/SparkPool02",
						"name": "SparkPool02",
						"type": "Spark",
						"endpoint": "https://wssynapse30062022.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkPool02",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "2.4",
						"nodeCount": 10,
						"cores": 8,
						"memory": 56
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"microsoft": {
								"language": "python"
							}
						},
						"source": [
							"%%pyspark\n",
							"df = spark.sql(\"SELECT * FROM LDB4.DADOS_POC_ANONIMIZADO_ENTRADA_S2_v2\")\n",
							"df.show(10)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.describe()"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pathcsv='abfss://fssynapse30062022@sasynapse30062022.dfs.core.windows.net/LakeDatabase1/DADOS_POC_ANONIMIZADO_ENTRADA_S2_v2_validacao.csv'\r\n",
							"pathparquet='abfss://fssynapse30062022@sasynapse30062022.dfs.core.windows.net/LakeDatabase1/DADOS_POC_ANONIMIZADO_ENTRADA_S2_v2_validacao.parquet'\r\n",
							""
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df = spark.read.options(inferSchema='TRUE',delimiter=';',header='TRUE').csv(pathcsv)\r\n",
							""
						],
						"outputs": [],
						"execution_count": 31
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.show(10)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.coalesce(1).write.parquet(pathparquet, mode = 'overwrite')"
						],
						"outputs": [],
						"execution_count": 33
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Read and write data from Azure Data Lake Storage Gen2')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "4bd6431e-b82f-417f-ae05-26ad1ad6c0eb"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "python"
					},
					"language_info": {
						"name": "python"
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"source": [
							"# Access data on Azure Data Lake Storage Gen2 (ADLS Gen2) with Synapse Spark\n",
							"\n",
							"Azure Data Lake Storage Gen2 (ADLS Gen2) is used as the storage account associated with a Synapse workspace. A synapse workspace can have a default ADLS Gen2 storage account and additional linked storage accounts. \n",
							"\n",
							"You can access data on ADLS Gen2 with Synapse Spark via following URL:\n",
							"    \n",
							"    abfss://<container_name>@<storage_account_name>.dfs.core.windows.net/<path>\n",
							"\n",
							"This notebook provides examples of how to read data from ADLS Gen2 account into a Spark context and how to write the output of Spark jobs directly into an ADLS Gen2 location.\n",
							"\n",
							"## Pre-requisites\n",
							"Synapse leverage AAD pass-through to access any ADLS Gen2 account (or folder) to which you have a **Blob Storage Contributor** permission. No credentials or access token is required. "
						]
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Load a sample data\n",
							"\n",
							"Let's first load the [public holidays](https://azure.microsoft.com/en-us/services/open-datasets/catalog/public-holidays/) of last 6 months from Azure Open datasets as a sample."
						]
					},
					{
						"cell_type": "code",
						"source": [
							"from azureml.opendatasets import PublicHolidays\n",
							"\n",
							"from datetime import datetime\n",
							"from dateutil import parser\n",
							"from dateutil.relativedelta import relativedelta\n",
							"\n",
							"\n",
							"end_date = datetime.today()\n",
							"start_date = datetime.today() - relativedelta(months=6)\n",
							"hol = PublicHolidays(start_date=start_date, end_date=end_date)\n",
							"hol_df = hol.to_spark_dataframe()"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"source": [
							"# Display 5 rows\n",
							"hol_df.show(5, truncate = False)"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "markdown",
						"source": [
							"## Write data to the default ADLS Gen2 storage\n",
							"\n",
							"We are going to write the spark dateframe to your default ADLS Gen2 storage account.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"from pyspark.sql import SparkSession\n",
							"from pyspark.sql.types import *\n",
							"\n",
							"# Primary storage info\n",
							"account_name = 'fill in your primary account name' # fill in your primary account name\n",
							"container_name = 'fill in your container name' # fill in your container name\n",
							"relative_path = 'fill in your relative folder path' # fill in your relative folder path\n",
							"\n",
							"adls_path = 'abfss://%s@%s.dfs.core.windows.net/%s' % (container_name, account_name, relative_path)\n",
							"print('Primary storage account path: ' + adls_path)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Save a dataframe as Parquet, JSON or CSV\n",
							"If you have a dataframe, you can save it to Parquet or JSON with the .write.parquet(), .write.json() and .write.csv() methods respectively.\n",
							"\n",
							"Dataframes can be saved in any format, regardless of the input format.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"parquet_path = adls_path + 'holiday.parquet'\n",
							"json_path = adls_path + 'holiday.json'\n",
							"csv_path = adls_path + 'holiday.csv'\n",
							"print('parquet file path: ' + parquet_path)\n",
							"print('json file pathï¼š ' + json_path)\n",
							"print('csv file path: ' + csv_path)"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"source": [
							"hol_df.write.parquet(parquet_path, mode = 'overwrite')\n",
							"hol_df.write.json(json_path, mode = 'overwrite')\n",
							"hol_df.write.csv(csv_path, mode = 'overwrite', header = 'true')"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Save a dataframe as text files\n",
							"If you have a dataframe that you want ot save as text file, you must first covert it to an RDD and then save that RDD as a text file.\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"# Define the text file path\n",
							"text_path = adls_path + 'holiday.txt'\n",
							"print('text file path: ' + text_path)"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"source": [
							"# Covert spark dataframe into RDD \n",
							"hol_RDD = hol_df.rdd\n",
							"type(hol_RDD)"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "markdown",
						"source": [
							"If you have an RDD, you can convert it to a text file like the following:\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							" # Save RDD as text file\n",
							"hol_RDD.saveAsTextFile(text_path)"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "markdown",
						"source": [
							"# Read data from the default ADLS Gen2 storage\n",
							""
						]
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Create a dataframe from parquet files\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"df_parquet = spark.read.parquet(parquet_path)"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Create a dataframe from JSON files\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"df_json = spark.read.json(json_path)"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Create a dataframe from CSV files\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"df_csv = spark.read.csv(csv_path, header = 'true')"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "markdown",
						"source": [
							"### Create an RDD from text file\n",
							""
						]
					},
					{
						"cell_type": "code",
						"source": [
							"text = sc.textFile(text_path)"
						],
						"outputs": [],
						"execution_count": 17
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LDB4')]",
			"type": "Microsoft.Synapse/workspaces/databases",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"Ddls": [
					{
						"ActionType": "CREATE",
						"OldEntity": null,
						"NewEntity": {
							"Name": "LDB4",
							"EntityType": "DATABASE",
							"Origin": {
								"Type": "SPARK"
							},
							"Properties": {
								"IsSyMSCDMDatabase": true
							},
							"Source": {
								"Provider": "ADLS",
								"Location": "abfss://fssynapse30062022@sasynapse30062022.dfs.core.windows.net/LDB4",
								"Properties": {
									"FormatType": "csv",
									"LinkedServiceName": "wssynapse30062022-WorkspaceDefaultStorage"
								}
							}
						},
						"Source": {
							"Type": "SPARK"
						}
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SparkPool01')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "Medium",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.1",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SparkPool02')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 10,
				"nodeSize": "Medium",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "2.4",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": false,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DedicatedPool2')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks",
			"apiVersion": "2019-06-01-preview",
			"properties": {},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default/synapse-ws-custstgacct--wssynapse30062022-sasynapse30062022')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks/managedPrivateEndpoints",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"privateLinkResourceId": "/subscriptions/241719b7-f326-42c8-87a0-fb0182d3a3c7/resourceGroups/rgsynapse30062022/providers/Microsoft.Storage/storageAccounts/sasynapse30062022",
				"groupId": "dfs",
				"fqdns": [
					"sasynapse30062022.dfs.core.windows.net"
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default/synapse-ws-sql--wssynapse30062022')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks/managedPrivateEndpoints",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"privateLinkResourceId": "/subscriptions/241719b7-f326-42c8-87a0-fb0182d3a3c7/resourceGroups/rgsynapse30062022/providers/Microsoft.Synapse/workspaces/wssynapse30062022",
				"groupId": "sql",
				"fqdns": [
					"wssynapse30062022.edfe3384-5f8c-45cd-9334-829c2d6695c5.sql.azuresynapse.net"
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default/synapse-ws-sqlOnDemand--wssynapse30062022')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks/managedPrivateEndpoints",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"privateLinkResourceId": "/subscriptions/241719b7-f326-42c8-87a0-fb0182d3a3c7/resourceGroups/rgsynapse30062022/providers/Microsoft.Synapse/workspaces/wssynapse30062022",
				"groupId": "sqlOnDemand",
				"fqdns": [
					"wssynapse30062022-ondemand.edfe3384-5f8c-45cd-9334-829c2d6695c5.sql.azuresynapse.net"
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		}
	]
}